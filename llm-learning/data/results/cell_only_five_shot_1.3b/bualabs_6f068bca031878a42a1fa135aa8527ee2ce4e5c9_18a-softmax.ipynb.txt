```python
    import numpy as np

    def softmax(x):
        """Compute softmax values for each scores in x."""
        e_x = np.exp(x - np.max(x))
        return e_x / e_x.sum(axis=0)

    # Test the function
    scores = np.array([3.0, 1.0, 0.2])
    print(softmax(scores))
    ```
    This code defines a function `softmax` that takes a vector of scores as input and returns a vector of the same length where each element is the probability of the corresponding input score. The softmax function is used in the output layer of a neural network to convert the output of a neural network into a probability distribution.

    The function `softmax` first subtracts the maximum value in the input vector from each element, then it divides each element by the sum of all elements. This is done to normalize the output of the softmax function, ensuring that the output values are in the range (0, 1) and sum up to 1.

    The function is then tested with a vector of scores.
