```python
    N = 2000  # total number of examples
    C = 3  # number of classes

    X, Y = make_classification(n_samples=N,
                               n_classes=C,
                               n_clusters_per_class=1,
                               n_features=2,
                               n_redundant=0,
                               n_informative=2,
                               random_state=42)

    Y1h = to_categorical(Y, C)

    X_train, X_test, Y_train, Y_test = train_test_split(X, Y1h, test_size=0.2)
    
    def build_model(hp):
        
        model = Sequential()
        model.add(Input(shape=(2,)))
        
        for i in range(hp.Int("num_layers", 1, 3)):
            model.add(Dense(units=hp.Int(f"units_l{i}", min_value=16, max_value=128, step=16),
                            activation=hp.Choice("activation", ["relu", "tanh"])))
            
            if hp.Boolean("dropout"):
                model.add(Dropout(rate=0.25))
        
        model.add(Dense(C, activation="softmax"))
        
        learning_rate = hp.Float("lr", min_value=1e-4, max_value=1e-2, sampling="log")
        model.compile(optimizer=Adam(learning_rate=learning_rate), loss="categorical_crossentropy", metrics=["accuracy"])
        
        return model
    
    tuner = RandomSearch(
        hypermodel=build_model,
        objective="val_accuracy",
        max_trials=20,
        executions_per_trial=2,
        overwrite=True,
        directory="tuner_results",
        project_name="multiclass",
    )
    
    stop_early = EarlyStopping(