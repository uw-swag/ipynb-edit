
    '''
    # data manipulation
    import pandas as pd

    # numpy arrays
    import numpy as np

    # data visualization
    import seaborn as sns
    import matplotlib.pyplot as plt
    import plotly.express as px

    sns.set()

    # NLP
    import string

    import spacy
    from spacy.tokens.doc import Doc
    from spacy.matcher import Matcher

    from wordcloud import WordCloud

    import nltk
    from nltk.probability import FreqDist

    import re

    # machine learning
    from sklearn.datasets import fetch_20newsgroups

    from sklearn.model_selection import train_test_split
    from sklearn.model_selection import GridSearchCV

    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
    from sklearn.preprocessing import LabelEncoder
    from sklearn.pipeline import Pipeline

    from sklearn.linear_model import LogisticRegression
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.ensemble import RandomForestClassifier

    from sklearn.metrics import classification_report
    from sklearn.metrics import confusion_matrix

    # TODO:
    # install the latest version of `sklearn` to use `plot_confusion_matrix` 
    # from sklearn.metrics import plot_confusion_matrix

    nlp = spacy.load('en_core_web_md', )
    for category in categories:
        plot_word_cloud(category,
                        categories_text_df[categories_text_df['category'] == category]['text'].values[0])
    def spacy_analyzer(document):
    
        # apply the language pipeline on the passed document
        # for quicker execution, disable `parser` and `ner` pipeline steps
        doc = nlp(document, disable=['parser', 'ner'])
    
        # clean document
        tokens = [token.lemma_.lower() for token in doc if is_clean_token