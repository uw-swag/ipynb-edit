```python
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn import datasets
    from sklearn.linear_model import SGDClassifier

    # Load iris dataset as an example
    iris = datasets.load_iris()
    X = iris.data
    y = iris.target

    # Create a linear model
    clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)

    # Train the model
    clf.fit(X, y)

    # Plot the decision boundary
    h = .02  # step size in the mesh
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

    # Put the result into a color plot
    Z = Z.reshape(xx.shape)
    plt.figure()
    plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel1)

    # Plot also the training points
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', s=20)
    plt.title('Decision surface at fit using Stochastic Gradient Descent')
    plt.xlabel('Sepal length')
    plt.ylabel('Sepal width')
    plt.show()
    ```
