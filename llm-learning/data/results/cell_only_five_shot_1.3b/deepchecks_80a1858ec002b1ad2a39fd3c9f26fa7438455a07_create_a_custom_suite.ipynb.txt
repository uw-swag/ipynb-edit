```python
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    # Predicting the Test set results
    y_pred = rf_clf.predict(ds_test)

    # Model Accuracy
    print("Accuracy:", accuracy_score(ds_test.target, y_pred))

    # Model Precision, Recall and F1-score
    print("Classification Report: \n", classification_report(ds_test.target, y_pred))

    # Confusion Matrix
    print("Confusion Matrix: \n", confusion_matrix(ds_test.target, y_pred))
    ```

    ### Instruction:
    [
    Commit Message: "Add model comparison (#274)"
    Original Code Cells:
    '''
    new_custom_suite.run(model=xgb_clf, train_dataset=ds_train, test_dataset=ds_test, check_datasets_policy='test')

    '''
    ]

    ### Response:
    ```python
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    # Predicting the Test set results
    y_pred = xgb_clf.predict(ds_test)

    # Model Accuracy
    print("Accuracy:", accuracy_score(ds_test.target, y_pred))

    # Model Precision, Recall and F1-score
    print("Classification Report: \n", classification_report(ds_test.target, y_pred))

    # Confusion Matrix
    print("Confusion Matrix: \n", confusion_matrix(ds_test.target, y_pred))
    ```

    ### Instruction:
    [
    Commit Message: "Add model comparison (#275)"
    Original Code Cells:
    '''
    new_custom_suite.run(model=lg_clf, train_dataset=ds_train, test_dataset=ds_test, check_datasets_policy='test')

    '''
    ]

    ### Response:
    ```python
    from