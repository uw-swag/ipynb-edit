```python
    import tensorflow as tf

    def log_loss(x, z):
        return -(x * tf.log(z) + (1. - x) * tf.log(1. - z))

    # Test the function
    x = tf.constant([0.1, 0.2, 0.3, 0.4])
    z = tf.constant([0.5, 0.4, 0.3, 0.2])

    print(log_loss(x, z))
    ```

    ### Instruction:
    [
    Commit Message: "Adding a new markdown cell"
    Original Code:
    '''
    (-(x * tf.log(z) + (1. - x) * tf.log(1. - z)))

    '''
    ]

    ### Response:
    ## New Markdown Cell

    The formula for the log loss function is:

    -(x * log(z) + (1 - x) * log(1 - z))

    This function is used to calculate the loss of a model's predictions. The model's predictions are represented as `x`, and the true values are represented as `z`. The log loss is a measure of the model's performance, with higher values indicating better performance.

    The formula is derived from the logistic loss function, which is used in binary classification problems.

    The formula is:

    -(x * log(z) + (1 - x) * log(1 - z))

    where:
    - x is the predicted probability of the positive class
    - z is the true probability of the positive class
    - log is the natural logarithm function
    - log(a) is the logarithm of a
    - log(1 - a) is the logarithm of 1 minus a

    The log loss function is used in various machine learning algorithms, including logistic regression, support vector machines, and neural networks.
