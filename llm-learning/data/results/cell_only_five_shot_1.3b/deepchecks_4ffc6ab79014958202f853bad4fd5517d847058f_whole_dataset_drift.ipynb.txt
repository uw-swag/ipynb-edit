```python
    import numpy as np
    from sklearn import datasets
    from sklearn.model_selection import train_test_split
    from sklearn.model_selection import ShuffleSplit
    import pandas as pd
    from sklearn.preprocessing import LabelEncoder # poderia ser LabelBinarizer
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.model_selection import GridSearchCV
    from sklearn.neighbors import KNeighborsClassifier
    from matplotlib import pyplot as plt
    from sklearn.metrics import classification_report
    %matplotlib inline
    plt.style.use('ggplot')
    class KNNClassifier(object):
        def __init__(self, n = 1):
            self.X_train = None
            self.y_train = None
            self.n = n

        def closest(self, row):
            """
            Retorna a classe respondente ao ponto mais próximo do dataset de treino.\
            É um exemplo de implementação do kNN com k=1.
            """
        
            # calcula as distâncias(norma L2) entre row e os pontos no dataset
            distances = np.linalg.norm(self.X_train - row, axis=1)
            # calcula os índices dos n pontos com menor distância para row
            smallest_n_ix = np.argpartition(distances, self.n)[:self.n]
            # calcula os labels dos pontos do passo anterior
            labels = self.y_train[smallest_n_ix]
        
            # retorna o label com a maior quantidade de ocorrências em labels
            return np.bincount(labels).argmax()

        def fit(self, training_data, training_labels):
            self.X_train = training_data
            self.y_train = training_labels
        
            return self

        def predict(self, to_classify):
            predictions = []
            for row in to_classify:
                label = self.closest(row)