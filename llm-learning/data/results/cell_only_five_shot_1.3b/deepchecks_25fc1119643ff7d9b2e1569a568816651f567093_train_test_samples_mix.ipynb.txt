```python
    import nltk
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize
    from nltk.stem import PorterStemmer
    from nltk.stem import WordNetLemmatizer
    from nltk.corpus import wordnet
    from nltk.corpus import nltk
    nltk.download('punkt')
    nltk.download('stopwords')
    nltk.download('wordnet')

    stop_words = set(stopwords.words('english'))
    ps = PorterStemmer()
    lemmatizer = WordNetLemmatizer()

    def get_wordnet_pos(treebank_tag):
        if treebank_tag.startswith('J'):
            return wordnet.ADJ
        elif treebank_tag.startswith('V'):
            return wordnet.VERB
        elif treebank_tag.startswith('N'):
            return wordnet.NOUN
        elif treebank_tag.startswith('R'):
            return wordnet.ADV
        else:
            return wordnet.NOUN

    def stem_word(word):
        return ps.stem(word)

    def lemmatize_word(word):
        return lemmatizer.lemmatize(word, get_wordnet_pos(wordnet_pos(word)))

    def remove_stopwords(word_list):
        return [word for word in word_list if word not in stop_words]

    def stem_and_lemmatize(word_list):
        return [stem_word(lemmatize_word(word)) for word in word_list]

    # Example usage:
    text = "This is a sample text for the NLTK library."
    word_list = word_tokenize(text)
    word_list = remove_stopwords(word_list)
    word_list = stem_and_lemmatize(word_list)
    print(word_list)
    ```
    '''
    '''
    ]
