```python
    import numpy as np

    def compute_cost(X, y, theta):
        m = len(y)
        h = X.dot(theta)
        cost = (1/(2*m)) * np.sum((h - y)**2)
        return cost

    def gradient_descent(X, y, theta, alpha, iterations):
        m = len(y)
        cost_history = np.zeros((iterations,1))

        for i in range(iterations):
            h = X.dot(theta)
            loss = h - y
            gradient = (1/m) * X.T.dot(loss)
            theta = theta - alpha * gradient
            cost_history[i] = compute_cost(X, y, theta)

        return (theta, cost_history)

    # Example usage:
    X = np.array([[1,1],[1,2],[1,3]])
    y = np.array([2,3,4]).reshape(-1,1)
    theta = np.array([0,0]).reshape(-1,1)
    alpha = 0.01
    iterations = 1000

    theta, cost_history = gradient_descent(X, y, theta, alpha, iterations)
    print(theta)
    ```

    This code implements gradient descent for linear regression. The `compute_cost` function computes the cost of the model given the input and output, and the `gradient_descent` function performs gradient descent to minimize the cost.

    The example usage demonstrates how to use the `gradient_descent` function to find the optimal values of theta that minimize the cost function for a linear regression model.
