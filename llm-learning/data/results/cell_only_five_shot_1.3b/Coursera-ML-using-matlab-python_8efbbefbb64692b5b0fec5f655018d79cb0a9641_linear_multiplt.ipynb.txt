
    '''
    #plot the j_cost
    plt.plot(J_history,color = 'b')
    plt.xlabel('iters')
    plt.ylabel('j_cost')
    plt.title('cost variety')
    plt.show()

    #predict (Note :normalize the feature with the train sets)
    X_t = ([[1650,3]] - mu) / sigma
    X_test = np.hstack((np.ones((1,1)),X_t))
    predict = X_test.dot(w)
    print 'Predicted price of a 1650 sq-ft, 3 br house (using normal equations)'
    print predict

    #compute the gradient by using Normal Equations  
    #without feature scaling and gradient descent
    w = normalEquation(XX,yy)
    print 'Theta computed from the normal equations:'
    print w

    '''
    ]

    ### Response:
    
    '''
    #plot the j_cost
    plt.plot(J_history,color = 'b')
    plt.xlabel('iters')
    plt.ylabel('j_cost')
    plt.title('cost variety')
    plt.show()

    #predict (Note :normalize the feature with the train sets)
    X_t = ([[1650,3]] - mu) / sigma
    X_test = np.hstack((np.ones((1,1)),X_t))
    predict = X_test.dot(w)
    print 'Predicted price of a 1650 sq-ft, 3 br house (using normal equations)'
    print predict

    #compute the gradient by using Normal Equations  
    #without feature scaling and gradient descent
    w = normalEquation(XX,yy)
    print 'Theta computed from the normal equations:'
    print w

    '''
    ]

    ### Response:
    
    '''
    #plot the j_cost
    plt.plot(J_history,color = 'b')
    plt.xlabel('iters')
   