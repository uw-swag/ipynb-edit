
The code you provided is for a neural network with two hidden layers, and it's using the `tf.layers.dense` function to create the layers. The output of the second hidden layer is not the output of the first hidden layer, which is the case in the original code.

The `tf.layers.dense` function creates a fully connected layer, and the output of this layer is the input to the next layer. In your case, the output of the second hidden layer is not the output of the first hidden layer, which is the case in the original code.

If you want to get the output of the second hidden layer, you should use the `get_tensor_by_name` function to get the tensor with the name "new_hidden4" and then use the `get_tensor_by_name` function to get the tensor with the name "new_outputs".

Here is the corrected code:

```python
reset_graph()

n_hidden4 = 20  # new layer
n_outputs = 10  # new layer

saver = tf.train.import_meta_graph("./my_model_final.ckpt.meta")

X = tf.get_default_graph().get_tensor_by_name("X:0")
y = tf.get_default_graph().get_tensor_by_name("y:0")

hidden3 = tf.get_default_graph().get_tensor_by_name("dnn/hidden4/Relu:0")

new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name="new_hidden4")
new_logits = tf.get_default_graph().get_tensor_by_name("new_outputs/BiasAdd:0")

with tf.name_scope("new_loss"):
    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)
    loss = tf.reduce_mean(xentropy, name="loss")

with tf.name_scope("new_eval"):
    correct =