```python
    import torch
    from torch import nn
    from torch.utils.data import DataLoader
    from torchvision import datasets, transforms

    class Trainer:
        def __init__(self, model, train_loader, test_loader, criterion, optimizer, num_epochs=10):
            self.model = model
            self.train_loader = train_loader
            self.test_loader = test_loader
            self.criterion = criterion
            self.optimizer = optimizer
            self.num_epochs = num_epochs

        def train(self):
            self.model.train()
            for epoch in range(self.num_epochs):
                running_loss = 0.0
                for images, labels in self.train_loader:
                    images = images.to(device)
                    labels = labels.to(device)

                    self.optimizer.zero_grad()

                    outputs = self.model(images)
                    loss = self.criterion(outputs, labels)

                    loss.backward()
                    self.optimizer.step()

                    running_loss += loss.item()

                print(f'Epoch {epoch+1}, Loss: {running_loss/len(self.train_loader)}')

        def test(self):
            self.model.eval()
            with torch.no_grad():
                correct = 0
                total = 0
                for images, labels in self.test_loader:
                    images = images.to(device)
                    labels = labels.to(device)

                    outputs = self.model(images)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                print(f'Accuracy on test set: {100 * correct / total}%')

    # Initialize the model, data loaders, and the trainer
    model = MyModel()
    train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)
    test_loader