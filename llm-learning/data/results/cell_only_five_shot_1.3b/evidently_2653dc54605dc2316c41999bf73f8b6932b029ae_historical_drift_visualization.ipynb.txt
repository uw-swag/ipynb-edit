```python
    #log into MLflow
    client = MlflowClient()

    #set experiment
    mlflow.set_experiment('Dataset Drift Analysis with Evidently')

    #start new run
    for date in experiment_batches:
        with mlflow.start_run() as run: 

            # Log parameters
            mlflow.log_param("begin", date[0])
            mlflow.log_param("end", date[1])

            # Log metrics
            metric = detect_dataset_drift(raw_data.loc[reference_dates[0]:reference_dates[1]], 
                                         raw_data.loc[date[0]:date[1]], 
                                         column_mapping=data_columns, 
                                         confidence=0.95,
                                         threshold=0.9,
                                         get_ratio=True)
            
            mlflow.log_metric('dataset drift', metric)

            print(run.info)
    ```

    This script logs the results of the dataset drift analysis into MLflow, a platform for managing the ML lifecycle, including experimentation, reproducibility, and deployment. The results of the dataset drift analysis are logged as metrics, which can be visualized in the MLflow UI.
