```python
    # Importing necessary libraries
    import spacy
    from spacy import displacy
    from collections import Counter

    # Load English tokenizer, tagger, parser, NER and word vectors
    nlp = spacy.load("en_core_web_sm")

    # Process whole documents
    text = ("The quick brown fox jumps over the lazy dog. "
            "The dog is running behind the fast. "
            "The fox is jumping on the lazy dog.")

    doc = nlp(text)

    # Analyze syntax
    print("Noun chunks:", [chunk.text for chunk in doc.noun_chunks])
    print("Verbs:", [token.lemma_ for token in doc if token.pos_ == "VERB"])

    # Find named entities, phrases and concepts
    for entity in doc.ents:
        print(entity.text, entity.label_)

    # Get text and parse entities
    text2 = ("The quick brown fox jumps over the lazy dog. "
             "The dog is running behind the fast. "
             "The fox is jumping on the lazy dog.")

    doc2 = nlp(text2)

    for entity in doc2.ents:
        print(entity.text, entity.label_)

    # Visualize the parsed text
    spacy.displacy.render(doc2, style="ent", jupyter="notebook")
    ```

    This script uses Spacy's Natural Language Processing (NLP) capabilities to perform Named Entity Recognition (NER) on the given text. The script first loads the "en_core_web_sm" model, which is a small English language model trained for web text. It then processes the text and analyzes the syntax, verbs, and named entities. Finally, it visualizes the parsed text using Spacy's displacy module.
