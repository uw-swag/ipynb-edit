```python
    # Import necessary libraries
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_squared_error
    from sklearn.preprocessing import PolynomialFeatures

    # Load the data
    df = pd.read_csv('data.csv')

    # Split the data into features and target
    X = df.drop('target', axis=1)
    y = df['target']

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Create a Polynomial Features object
    poly = PolynomialFeatures(degree=2)

    # Transform the features to polynomial features
    X_train_poly = poly.fit_transform(X_train)
    X_test_poly = poly.transform(X_test)

    # Create a Linear Regression model
    model = LinearRegression()

    # Train the model
    model.fit(X_train_poly, y_train)

    # Make predictions
    y_pred = model.predict(X_test_poly)

    # Calculate the mean squared error of the predictions
    mse = mean_squared_error(y_test, y_pred)

    print(f'Mean Squared Error: {mse}')

    # Plot the actual vs predicted values
    plt.figure(figsize=(10, 6))
    sns.scatterplot(y_test, y_pred)
    plt.xlabel('Actual')
    plt.ylabel('Predicted')
    plt.title('Actual vs Predicted')
    plt.show()
    ```
    This script loads a dataset, splits it into a training set and a testing set, creates a Polynom