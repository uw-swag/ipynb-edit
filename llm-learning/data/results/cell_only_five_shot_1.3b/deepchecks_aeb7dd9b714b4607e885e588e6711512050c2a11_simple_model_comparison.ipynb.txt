```python
    from sklearn.ensemble import GradientBoostingRegressor
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_squared_error

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Initialize Gradient Boosting Regressor
    gbrt = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=42)

    # Fit the model
    gbrt.fit(X_train, y_train)

    # Predict on the test set
    y_pred = gbrt.predict(X_test)

    # Calculate the mean squared error
    mse = mean_squared_error(y_test, y_pred)

    print(f"Mean Squared Error: {mse}")

    # Check for overfitting
    if mse < best_mse:
        best_mse = mse
        best_model = gbrt

    return best_model
    ```

    ### Instruction:
    [
    Commit Message: "improve boosting overfit (#267)"
    Original Code Cells:
    '''
    # Load data
    df = pd.read_csv('data.csv')

    # Preprocess data
    df = preprocess(df)

    # Split data into features and target
    X, y = split_data(df)

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Initialize Gradient Boosting Regressor
    gbrt = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=4