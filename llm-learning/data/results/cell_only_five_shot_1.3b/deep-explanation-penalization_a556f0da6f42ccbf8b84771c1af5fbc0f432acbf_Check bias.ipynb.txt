```python
    import numpy as np
    from sklearn.metrics import mean_squared_error

    # Assuming you have a function `predict_proba` that returns the probabilities of the positive class
    def predict_proba(X):
        return np.random.rand(X.shape[0])

    # Assuming you have a function `get_labels` that returns the true labels
    def get_labels(X):
        return np.random.randint(0, 2, X.shape[0])

    # Generate some random data
    X = np.random.rand(1000, 10)
    y_true = get_labels(X)

    # Predict probabilities
    y_pred = predict_proba(X)

    # Compute the mean squared error
    mse = mean_squared_error(y_true, y_pred)

    print(f"Mean Squared Error: {mse}")
    ```
    '''

    ### Instruction:
    [
    Commit Message: "added results and code for eval on iid"
    Original Code Cells:
    '''
    
    '''
    ]

    ### Response:
    ```python
    import numpy as np
    from sklearn.metrics import mean_squared_error

    # Assuming you have a function `predict_proba` that returns the probabilities of the positive class
    def predict_proba(X):
        return np.random.rand(X.shape[0])

    # Assuming you have a function `get_labels` that returns the true labels
    def get_labels(X):
        return np.random.randint(0, 2, X.shape[0])

    # Generate some random data
    X = np.random.rand(1000, 10)
    y_true = get_labels(X)

    # Predict probabilities
    y_pred = predict_proba(X)

    # Compute the mean squared error
    mse = mean_squared_error(y_true, y_pred)

    print