```python
    # Example 1:
    # ------------------------
    # This is a simple example of how to use the `start_or_get_spark` function from the `common.spark_utils` module.
    # 
    # The function takes two parameters:
    # 1. `packages`: A list of Maven coordinates of the packages to be installed.
    # 2. `repository`: The URL of the Maven repository.
    # 
    # The function returns a SparkSession object.
    # 
    # Here is an example of how to use it:
    # 
    # ```python
    # from reco_utils.common.spark_utils import start_or_get_spark
    # 
    # packages = ["org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.1"]
    # repository = "https://repo.maven.org/maven2"
    # 
    # spark = start_or_get_spark(packages, repository)
    # ```
    # 
    # Example 2:
    # ------------------------
    # This is a simple example of how to use the `is_databricks` function from the `common.notebook_utils` module.
    # 
    # The function checks if the current notebook is running in Databricks.
    # 
    # Here is an example of how to use it:
    # 
    # ```python
    # from reco_utils.common.notebook_utils import is_databricks
    # 
    # if is_databricks():
    #     print("The current notebook is running in Databricks.")
    # else:
    #     print("The current notebook is not running in Databricks.")
    # ```
    # 
    # Example 3:
    # ------------------------
    # This is a simple example of how to use the `load_spark_df` function from the `dataset.criteo` module.
    # 
    # The function loads a DataFrame from a CSV file.
    # 
   