```python
    # Adding Small Batch Size and Running Batch Norm Sections
    class RunningBatchNorm(torch.nn.Module):
        def __init__(self, num_features, eps=1e-5, momentum=0.1):
            super(RunningBatchNorm, self).__init__()
            self.num_features = num_features
            self.eps = eps
            self.momentum = momentum
            self.weight = torch.nn.Parameter(torch.Tensor(num_features).uniform_(-0.01, 0.01))
            self.bias = torch.nn.Parameter(torch.Tensor(num_features).uniform_(-0.01, 0.01))
            self.register_buffer('running_mean', torch.zeros(num_features))
            self.register_buffer('running_var', torch.ones(num_features))

        def forward(self, x):
            if x.dim() != 4:
                raise ValueError('Expected 4D input, got {}D'.format(x.dim()))
            N, C, H, W = x.size()
            running_mean = self.running_mean.repeat(N, C).unsqueeze(2).unsqueeze(3)
            running_var = self.running_var.repeat(N, C).unsqueeze(2).unsqueeze(3)
            x = (x - running_mean) / torch.sqrt(running_var + self.eps)
            x = x * self.weight.unsqueeze(0).unsqueeze(0).unsqueeze(2).unsqueeze(3)
            x = x + self.bias.unsqueeze(0).unsqueeze(0).unsqueeze(2).unsqueeze(3)
            return x

    class SmallBatchNorm(torch.nn.Module):
        def __init__(self, num_features, eps=1e-5, momentum=0.1):
            super(SmallBatchNorm, self).__init__()
            self.num_features = num_features
           