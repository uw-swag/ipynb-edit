
    '''
    #Deleted empty Notebook
    '''

    ### Instruction:
    [
    Commit Message: "Added missing imports"
    Original Code:
    '''
    #To help us perform math operations
    import numpy as np
    #to plot our data and model visually
    from matplotlib import pyplot as plt
    %matplotlib inline

    #Step 1 - Define our data

    #Input data - Of the form [X value, Y value, Bias term]
    X = np.array([
        [-2,4,-1],
        [4,1,-1],
        [1, 6, -1],
        [2, 4, -1],
        [6, 2, -1],
    ])

    #Associated output labels - First 2 examples are labeled '-1' and last 3 are labeled '+1'
    y = np.array([-1,-1,1,1,1])

    #lets plot these examples on a 2D graph!
    #for each example
    for d, sample in enumerate(X):
        # Plot the negative samples (the first 2)
        if d < 2:
            plt.scatter(sample[0], sample[1], s=120, marker='_', linewidths=2)
        # Plot the positive samples (the last 3)
        else:
            plt.scatter(sample[0], sample[1], s=120, marker='+', linewidths=2)

    # Print a possible hyperplane, that is seperating the two classes.
    #we'll two points and draw the line between them (naive guess)
    plt.plot([-2,6],[6,0.5])

    #lets perform stochastic gradient descent to learn the seperating hyperplane between both classes

    def svm_sgd_plot(X, Y):
        #Initialize our SVMs weight vector with zeros (3 values)
        w = np.zeros(len(X[0]))
        #The learning rate
        eta = 1
        #how many