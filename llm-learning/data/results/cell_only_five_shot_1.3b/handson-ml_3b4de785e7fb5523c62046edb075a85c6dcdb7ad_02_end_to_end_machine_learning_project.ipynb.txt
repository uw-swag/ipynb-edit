```
    ## Exercise 5: Hyperparameter tuning

    ## Chapter 2: Machine Learning Pipeline

    ## Exercise 5: Hyperparameter tuning

    ## In this exercise, we will use a pipeline to prepare the data, select the best features, and then train a model.

    ## We will use a grid search to find the best hyperparameters for the model.

    ## The pipeline will be as follows:

    ## 1. Preparation:
    ##   - Imputation: Replace missing values with the median of the respective column.
    ##   - Scaling: Standardize the data.
    ##   - Pipeline: Create a pipeline that first imputes the missing values, then scales the data.

    ## 2. Feature Selection:
    ##   - K-Fold Cross Validation: Select the best 'k' features using K-Fold Cross Validation.

    ## 3. Model Training:
    ##   - Grid Search: Use grid search to find the best hyperparameters for the model.

    ## The hyperparameters to tune are:
    ## - preparation__num_pipeline__imputer__strategy
    ## - feature_selection__k

    ## The scoring metric to use is:
    ## - neg_mean_squared_error

    ## The number of jobs to run concurrently for the grid search is:
    ## - 4

    ## The verbosity of the grid search is:
    ## - 2

    ## The number of folds for the K-Fold Cross Validation is:
    ## - 5

    ## The number of rows to use for fitting the model is:
    ## - 10000

    ## The number of rows to use for testing the model is:
    ## - 2000

    ## The number of rows to use for training the model is:
    ## - 5000

    ## The number of rows to use for validating the model is:
    ## - 1000

    ## The number of