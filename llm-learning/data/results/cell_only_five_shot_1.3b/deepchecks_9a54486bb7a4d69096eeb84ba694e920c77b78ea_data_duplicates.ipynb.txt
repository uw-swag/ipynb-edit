```python
    from deepchecks.checks.integrity.data_duplicates import DataDuplicates
    from deepchecks.base import Dataset, Suite
    from datetime import datetime
    import pandas as pd

    from deepchecks.datasets.classification.phishing import load_data

    phishing_dataset = load_data(as_train_test=False, data_format='DataFrame')
    phishing_dataset

    # Split the dataset into train and test
    train_dataset, test_dataset = phishing_dataset.split(0.8)

    # Run the DataDuplicates check on the train dataset
    DataDuplicates().run(train_dataset)

    # Run the DataDuplicates check on the test dataset
    DataDuplicates().run(test_dataset)
    ```

    This code will split the dataset into 80% for training and 20% for testing, and then it will run the DataDuplicates check on both datasets.
