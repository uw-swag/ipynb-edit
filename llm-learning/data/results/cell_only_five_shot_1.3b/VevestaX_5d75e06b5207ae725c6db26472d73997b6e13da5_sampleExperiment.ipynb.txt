
    # Importing necessary libraries
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_squared_error
    from sklearn.preprocessing import PolynomialFeatures

    # Generating some random data
    np.random.seed(0)
    X = np.random.randn(100, 1)
    y = 2 + 3 * X + np.random.randn(100, 1)

    # Splitting the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Training a linear regression model
    lin_reg = LinearRegression()
    lin_reg.fit(X_train, y_train)

    # Making predictions
    y_pred = lin_reg.predict(X_test)

    # Evaluating the model
    mse = mean_squared_error(y_test, y_pred)
    print(f"Mean Squared Error: {mse}")

    # Plotting the results
    plt.scatter(X_test, y_test, color='blue', label='Actual')
    plt.scatter(X_test, y_pred, color='green', label='Predicted')
    plt.legend()
    plt.show()

    # Experiment 1: Adding more features
    X_train_poly = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X_train)
    X_test_poly = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X_test)

    lin_reg_poly = LinearRegression()
    lin_reg_poly.fit(X_train_poly, y_train)

    y_pred_poly = lin_reg_poly.predict(X