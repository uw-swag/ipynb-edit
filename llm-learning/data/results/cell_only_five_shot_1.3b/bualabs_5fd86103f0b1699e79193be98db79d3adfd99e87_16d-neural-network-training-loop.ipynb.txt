
    Here is the refactored code. I have refactored the code to get data in batches.

    ```python
    # e = epoch number
    for e in range(epoch):
        # b = batch number
        for b in range(0, n, bs):
            start_b = b
            end_b = min(b + bs, n)
            xb = x_train[start_b:end_b]
            yb = y_train[start_b:end_b]
            loss = loss_func(model(xb), yb)

            # Metrics
            acc = accuracy(model(xb), yb)
            losses.append(loss); metrics.append(acc)
        
            # Backpropagation
            loss.backward()
        
            # Update Wight and Bias with SGD
            with torch.no_grad():
                for l in model.layers:
                    if hasattr(l, 'weight'):
                        l.weight -= l.weight.grad * lr
                        l.bias   -= l.bias.grad * lr 
                        l.weight.grad.zero_()
                        l.bias.grad.zero_()
    ```

    This refactored code will get data in batches instead of one by one. The batch size `bs` is defined as a global variable at the start of the script.

    Please note that this refactoring is based on the assumption that the data is divided into batches of size `bs`. If the data is not divided into batches of size `bs`, you may need to adjust the code accordingly.
