data = pd.read_csv('../input/train.csv')
test = pd.read_csv('../input/test.csv')
X_train = data.drop('id', axis=1)
X_train = X_train.drop('target', axis=1)
Y_train = LabelEncoder().fit_transform(data.target.values)
X_test = test.drop('id', axis=1)
Xtrain, Xtest, ytrain, ytest = train_test_split(X_train, Y_train, test_size=0.20, random_state=36)
clf = RandomForestClassifier(n_estimators=300, n_jobs=-1, criterion = 'gini')
calibrated_clf = CalibratedClassifierCV(clf, method='isotonic', cv=5)
calibrated_clf.fit(Xtrain, ytrain)

y_val = calibrated_clf.predict_proba(Xtest)
y_submit = calibrated_clf.predict_proba(X_test)
print("Loss on validation set: ", log_loss(ytest, y_val, eps=1e-15, normalize=True))
params = {"objective": "multi:softprob", "num_class": 9}
gbm = xgb.train(params, xgb.DMatrix(X_train, Y_train), 20)
Y_pred = gbm.predict(xgb.DMatrix(X_test))
y = 0.2 * Y_pred + 0.8 * y_submit
