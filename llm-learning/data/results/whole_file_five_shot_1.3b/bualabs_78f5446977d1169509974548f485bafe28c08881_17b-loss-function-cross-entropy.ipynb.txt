```python
    <Cell_0>
    import torch
    from torch import tensor
    import matplotlib.pyplot as plt
    <\Cell_0>
    <Cell_1>
    y = tensor([0, 1, 2, 0, 0, 1, 0, 2, 2, 1])
    y
    <\Cell_1>
    <Cell_2>
    n, c = len(y), y.max()+1
    <\Cell_2>
    <Cell_3>
    y_onehot = torch.zeros(n, c)
    y_onehot[torch.arange(n), y] = 1
    y_onehot
    <\Cell_3>
    <Cell_4>
    yhat =  tensor([[3., 2., 1.],
                    [5., 6., 2.],
                    [0., 0., 5.],
                    [2., 3., 1.],
                    [5., 4., 3.],
                    [1., 0., 3.],
                    [5., 3., 2.],
                    [2., 2., 4.],
                    [8., 5., 3.],
                    [3., 4., 0.]])
    <\Cell_4>
    <Cell_5>
    def log_softmax(z):
        z = z - z.max(-1, keepdim=True)[0]
        exp_z = torch.exp(z)
        sum_exp_z = torch.sum(exp_z, -1, keepdim=True)
        return (exp_z / sum_exp_z).log()
    <\Cell_5>
    <Cell_6>
    log_softmax(yhat)
    <\Cell_6>
    <Cell_7>
    yhat.argmax(1)
    <\Cell_7>
    <Cell_8>
    y
    <\Cell_8>
    <Cell_9>
    (yhat.argmax(1) == y).sum()
    <\Cell_9>
    <Cell_10>
    # log_pro