
    n_epochs = 100
    batch_size = 50

    with tf.Session() as sess:
        init.run()
        for epoch in range(n_epochs):
            rnd_idx = np.random.permutation(len(X_train2))
            for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):
                X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]
                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})

    print(epoch, "Train loss:", loss_val)

    n_epochs = 100
    batch_size = 50

    with tf.Session() as sess:
        init.run()
        for epoch in range(n_epochs):
            rnd_idx = np.random.permutation(len(X_train2))
            X_batch, y_batch = X_train2[rnd_idx], y_train2[rnd_idx]
            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
        print(epoch, "Train loss:", loss_val)

    n_epochs = 100
    batch_size = 50

    with tf.Session() as sess:
        init.run()
        for epoch in range(n_epochs):
            rnd_idx = np.random.permutation(len(X_train2))
            X_batch, y_batch = X_train2[rnd_idx], y_train2[rnd_idx]
            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
        print(epoch, "Train loss:", loss_val)

    n_epochs = 100
    batch_size = 50

    with tf.Session() as s