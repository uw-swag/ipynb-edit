```
    <Cell_0>
    import numpy as np
    import matplotlib.pyplot as plt

    from tensorflow.keras.layers import Input, Dense
    from tensorflow.keras.models import Model
    <\Cell_0>
    <Cell_1>
    X = np.random.uniform(size=500, low=-1/2, high=1/2)
    Y = 1.75 + np.sin(2*np.pi * X) + 1 * np.sin(3*np.pi * X + 1.5) + .05 * np.random.normal(size=len(X))
    Y = Y/np.max(Y)
    <\Cell_1>
    <Cell_2>
    # set up the model
    inputs = Input(shape=(1,))
    z = Dense(30, activation='sigmoid')(inputs)
    z = Dense(1, activation='linear')(z)
    model = Model(inputs, z)

    # compile the model
    model.compile(loss="mse", optimizer="adam")

    # train the model
    history = model.fit(X, Y, epochs=2000, batch_size=8, verbose=0)
    <\Cell_2>
    <Cell_3>
    Xt = np.linspace(-1/2, 1/2)
    Yt = model.predict(Xt)

    plt.plot(Xt, Yt, color='C0', label='model')
    plt.scatter(X,Y, alpha=.2, color='C1', label='examples')
    plt.legend()
    plt.grid()
    plt.show()
    <\Cell_3>
    ```

    The code above is a simple example of how to use function approximation capabilities of Deep Neural Networks (DNNs) with TensorFlow. The DNN is a simple model with one hidden layer, and the function approximation is achieved by the Dense layer. The model is trained to predict the output Y from the input X. The model