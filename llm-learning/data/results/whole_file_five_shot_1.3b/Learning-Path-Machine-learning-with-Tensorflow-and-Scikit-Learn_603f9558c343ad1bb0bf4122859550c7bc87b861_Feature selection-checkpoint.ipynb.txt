```python
    # Module 03: Code files added
    # This module includes the code for creating a SparkSession, creating DataFrames, and performing operations on them.

    # Import necessary libraries
    import pandas as pd
    import numpy as np
    import pyspark.sql.functions as F
    from pyspark.sql import SparkSession
    from pyspark.sql.window import Window
    from pyspark.sql.types import StructType, StructField, StringType, Row, ArrayType, IntegerType, FloatType

    # Specify parameters
    TOP_K = 2
    RECOMMEND_SEEN = True
    SIMILARITY = 'jaccard'

    # Create a SparkSession
    spark = SparkSession \
        .builder \
        .appName("SAR pySpark") \
        .master("local[*]") \
        .config("spark.driver.memory", "2g") \
        .config("spark.executor.memory", "8g") \
        .config("spark.yarn.executor.memoryOverhead", "3g") \
        .config("spark.memory.fraction", "0.9") \
        .config("spark.memory.stageFraction", "0.3") \
        .config("spark.executor.instances", 1) \
        .config("spark.executor.heartbeatInterval", "36000s") \
        .config("spark.network.timeout", "10000000s") \
        .config("spark.driver.maxResultSize", "50g") \
        .config("spark.sql.shuffle.partitions", "4") \
        .getOrCreate()

    # Create DataFrames
    d_train = {
        'customerID': [1,1,1,2,2,3,3],
        'itemID':     [1,2,3,4,5,6,1],
        'rating':     [5,5,5,1,1,3,5]
    }
    pdf_train = pd.DataFrame