
    The code you've provided is a major update of NLP-based feature engineering. It includes the following changes:

    1. Importing the necessary libraries and setting up a Spark session.
    2. Reading JSON files from a specified location and printing their schema.
    3. Showing the first 5 rows of the dataframe.
    4. Counting the number of rows in the dataframe.
    5. Splitting the 'date' column into an array of timestamps.
    6. Creating a temporary view for each dataframe.
    7. Performing some transformations on the dataframes and creating a final dataframe.
    8. Printing the schema of the final dataframe.
    9. Showing the first 5 rows of the final dataframe.
    10. Counting the number of rows in the final dataframe.
    11. Writing the final dataframe to JSON files.

    The code also includes the following steps:

    1. Splitting the original dataframe into training and testing dataframes.
    2. Creating a new dataframe with features from the text data.
    3. Creating a new dataframe with features from the non-text data.
    4. Writing the training and testing dataframes to JSON files.

    The final dataframe, all_data, includes features from both text and non-text data.
