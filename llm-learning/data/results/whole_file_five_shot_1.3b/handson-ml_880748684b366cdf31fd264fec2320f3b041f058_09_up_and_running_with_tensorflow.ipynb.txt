
    n_epochs = 1000
    n_batches = int(np.ceil(m / batch_size))

    print("Epoch:", n_epochs)
    print("  batch size:", batch_size)
    print("  learning_rate:", learning_rate)
    print("  training: ", end="")

    y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y, learning_rate)

    print("  precision:", precision_score(y_test, y_proba)
    print("  recall:", recall_score(y_test, y_proba))
<\Cell_139>
<Cell_40>
<Cell_40>
y_pred = y_proba_val
<\Cell_40>
<Cell_41>
y_proba, summary_str = sess.run([loss, summary_str], feed_dict={X: X_test, y: y_test})
<\Cell_41>
<Cell_42>
y_proba, summary_str = sess.run([loss, summary_str], feed_dict={X: X_test, y: y_test})
<\Cell_42>
<Cell_42>
y_proba, summary_str = sess.run([y_proba, summary_str], feed_dict={X: X_test, y: y_test})
<\Cell_42>
<Cell_43>
y_proba, summary_str = sess.run([y_proba, summary_str], feed_dict={X: X_test, y: y_test})
<\Cell_43>
<Cell_44>
y_proba, summary_str = sess.run([y_proba, summary_str], feed_dict={X: X_test, y: y_test})
<\Cell_44>
<Cell_44>
y_proba, summary_str = sess.run([y_proba, summary_str],