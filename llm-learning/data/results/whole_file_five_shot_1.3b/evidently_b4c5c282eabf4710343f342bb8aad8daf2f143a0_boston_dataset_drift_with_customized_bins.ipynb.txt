```python
    from pyspark.ml.feature import VectorAssembler
    from pyspark.ml.linalg import Vector
    from pyspark.sql.functions import col

    # Assuming df is your DataFrame and it has columns 'col1', 'col2', 'col3'
    column_mapping = {
        'col1': 'feature1',
        'col2': 'feature2',
        'col3': 'feature3'
    }

    # Create a VectorAssembler
    assembler = VectorAssembler(
        inputCols=['feature1', 'feature2', 'feature3'],
        outputCol="features")

    # Transform the DataFrame
    df = assembler.transform(df)

    # Create a new column for bins
    df = df.withColumn("bin", (col("features")[0] / 10).cast("integer"))

    # Configure dataset drift calculation
    from pyspark.ml.evaluation import BinaryClassificationEvaluator

    evaluator = BinaryClassificationEvaluator(rawPredictionCol="rawPrediction")

    # Configure bins customization
    from pyspark.ml.feature import Bucketizer

    bucketizer = Bucketizer(
        inputCol="features",
        outputCol="bins",
        splits=[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]
    )

    df = bucketizer.transform(df)

    # Show the DataFrame
    df.show()
    ```
