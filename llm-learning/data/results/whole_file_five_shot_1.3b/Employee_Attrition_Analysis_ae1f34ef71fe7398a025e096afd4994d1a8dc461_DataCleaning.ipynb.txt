```
    #prepare for RDS connection
    !pip install psycopg2

    # dependencies
    import pandas as pd
    import sqlalchemy
    from sqlalchemy import create_engine
    from sqlalchemy import Column, Integer, String, ForeignKey, create_engine, text
    import psycopg2
    from getpass import getpass
    from sklearn.preprocessing import OneHotEncoder, LabelEncoder

    # SQL Alchemy connection from RDS
    secret = getpass('Enter the secret value: ')

    args ={
        'host':"ogdataset.c11hekhsylui.us-west-1.rds.amazonaws.com",
        'port':'5432',
        'database':"og_dataset",
        'user':"attritionProject",
        'password':secret
    }

    engine = create_engine("postgresql://{user}:{password}@{host}:{port}/{database}".format(**args))
    engine.connect()

    # read in csv
    file_path = "../resources/IBM_employee_data.csv"
    attrition_df = pd.read_csv(file_path)
    attrition_df.head()

    # determine if any missing values and data types for columns
    attrition_df.info()

    # column names
    attrition_df.columns

    # ambiguous/unnecessary columns - only going to keep MonthlyIncome
    attrition_df[["DailyRate", "HourlyRate", "MonthlyIncome", "MonthlyRate", "StandardHours", "Over18"]]

    # these columns are either unique identifiers, ambiguous or constant thru each column
    columns_to_drop = ["DailyRate", "HourlyRate", "MonthlyRate", "StandardHours", "EmployeeCount", 
                       "EmployeeNumber", "Over18"]

    # drop the columns
    attrition_df.drop(columns=columns_to_drop, inplace=True)

    # send to csv to use in both Machine Learning Models