```python
    from sklearn.feature_extraction.text import CountVectorizer
    from sklearn.feature_extraction.text import TfidfTransformer
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.pipeline import Pipeline
    from sklearn.datasets import fetch_20newsgroups

    # Load 20 newswgroups dataset
    dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))

    # Create a text/string vectorizer
    text_clf = Pipeline([
        ('vect', CountVectorizer()),
        ('tfidf', TfidfTransformer()),
        ('clf', MultinomialNB()),
    ])

    # Train the model
    text_clf.fit(dataset.data, dataset.target)

    # Predict the category of a new sample
    sample = ["The MLc 225 is a very good product"]
    prediction = text_clf.predict(sample)

    print(prediction)
    ```

    ### Explanation:
    This Python script uses the `CountVectorizer` and `TfidfTransformer` from `sklearn` to convert text data into a format that can be used by a machine learning model. The `MultinomialNB` model is then used to classify the text data.

    The `fetch_20newsgroups` function from `sklearn.datasets` is used to load the 20 Newsgroups dataset, which is a collection of approximately 20,000 newsgroup documents, partitioned across 20 different newsgroups.

    The `Pipeline` class from `sklearn` is used to create a pipeline that first converts the text data into a vector format, then transforms the vector into a TF-IDF representation, and finally trains a Multinomial Naive Bayes classifier on the data.

    The `predict` method of the pipeline is then used to classify a new sample of text.

    The predicted category of the sample is printed to the console.
