
    '''
    Commit Message: "removing useless git LFS"
    Original Code Cells:
    '''
    <Cell_0>
    import pandas as pd
    import numpy as np
    import re
    import nltk
    <\Cell_0>
    <Cell_1>
    corpus = ['The sky is blue and beautiful.',
              'Love this blue and beautiful sky!',
              'The quick brown fox jumps over the lazy dog.',
              'The brown fox is quick and the blue dog is lazy!',
              'The sky is very blue and the sky is very beautiful today',
              'The dog is lazy but the brown fox is quick!'    
    ]
    labels = ['weather', 'weather', 'animals', 'animals', 'weather', 'animals']
    corpus = np.array(corpus)
    corpus_df = pd.DataFrame({'Document': corpus, 
                              'Category': labels})
    corpus_df = corpus_df[['Document', 'Category']]
    corpus_df
    <\Cell_1>
    <Cell_2>
    wpt = nltk.WordPunctTokenizer()
    stop_words = nltk.corpus.stopwords.words('english')

    def normalize_document(doc):
        # lower case and remove special characters\whitespaces
        doc = re.sub(r'[^a-zA-Z0-9\s]', '', doc, re.I)
        doc = doc.lower()
        doc = doc.strip()
        # tokenize document
        tokens = wpt.tokenize(doc)
        # filter stopwords out of document
        filtered_tokens = [token for token in tokens if token not in stop_words]
        # re-create document from filtered tokens
        doc = ' '.join(filtered_tokens)
        return doc

    normalize_corpus = np.vectorize(normalize_document)
    <\Cell_2>
    <Cell_3>
    norm_corpus = normalize_corpus(corpus)
    norm_corpus
    <