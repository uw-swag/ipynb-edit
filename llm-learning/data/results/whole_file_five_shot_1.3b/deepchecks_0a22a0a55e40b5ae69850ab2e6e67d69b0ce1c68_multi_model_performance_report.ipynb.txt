```python
    # Add check context (#700)
    from deepchecks.base import Dataset
    from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    from deepchecks.checks.performance import MultiModelPerformanceReport

    iris = load_iris(as_frame=True)
    train, test = train_test_split(iris.frame, test_size=0.33, random_state=42)

    train_ds = Dataset(train, label="target")
    test_ds = Dataset(test, label="target")

    clf1 = AdaBoostClassifier().fit(train_ds.features_columns, train_ds.label_col)
    clf2 = RandomForestClassifier().fit(train_ds.features_columns, train_ds.label_col)
    clf3 = DecisionTreeClassifier().fit(train_ds.features_columns, train_ds.label_col)

    MultiModelPerformanceReport().run(train_ds, test_ds, [clf1, clf2, clf3])
    ```

    This commit adds a check context to the `MultiModelPerformanceReport`. The context is a string that describes the purpose of the check. In this case, the context is "Evaluating the performance of the models on the iris dataset".
