```python
    import numpy as np
    import pandas as pd
    from keras.models import Sequential
    from keras.layers import Dense
    from keras.optimizers import Adam
    from rl.agents.dqn import DQNAgent
    from rl.memory import SequentialMemory
    from rl.policy import EpsGreedyQPolicy

    # Environment
    n_actions = 2
    n_states = 4

    # Agent
    memory = SequentialMemory(limit=50000, window_length=1)
    policy = EpsGreedyQPolicy()
    dqn = DQNAgent(model='linear_fa', nb_actions=n_actions, nb_steps_warmup=1000,
                   memory=memory, nb_steps_exploration=1000, policy=policy,
                   gamma=0.99, target_model_update=1e-3,
                   exploration_fraction=0.1, print_freq=10)

    # Training
    dqn.compile(Adam(learning_rate=0.001), metrics=['mae'])
    dqn.fit(env, nb_steps=50000, visualize=True, verbose=2)

    # Save model
    dqn.save_model('dqn_cartpole')
    ```
