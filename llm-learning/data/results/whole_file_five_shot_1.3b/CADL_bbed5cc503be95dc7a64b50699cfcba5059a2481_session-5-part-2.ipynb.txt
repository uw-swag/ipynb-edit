```
    ## Markdown:
    The code has been successfully run and the output is as expected.

    ## Code:
    ```python
    import tensorflow as tf
    from six.moves import urllib
    script = 'http://www.awesomefilm.com/script/biglebowski.txt'
    txts = []
    f, _ = urllib.request.urlretrieve(script, script.split('/')[-1])
    with open(f, 'r') as fp:
        txt = fp.read()
    txt = "\n".join([txt_i.strip()
                     for txt_i in txt.replace('\t', '').split('\n')
                     if len(txt_i)])
    len(txt)
    vocab = list(set(txt))
    vocab.sort()
    len(vocab)
    print(vocab)
    encoder = OrderedDict(zip(vocab, range(len(vocab))))
    decoder = OrderedDict(zip(range(len(vocab)), vocab))
    batch_size = 100
    sequence_length = 50
    n_cells = 128
    n_layers = 3
    n_chars = len(vocab)
    X = tf.placeholder(tf.int32, shape=(None, sequence_length), name='X')
    Y = tf.placeholder(tf.int32, shape=(None, sequence_length), name='Y')
    embedding = tf.get_variable("embedding", [n_chars, n_cells])
    Xs = tf.nn.embedding_lookup(embedding, X)
    Xs = [tf.squeeze(seq, [1]) for seq in tf.split(1, sequence_length, Xs)]
    cells = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_cells, state_is_tuple=True, forget_bias=1.0)
    initial_state = cells.zero_state