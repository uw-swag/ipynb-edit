
    '''
    [
    Commit Message: "Feature Importance"
    Original Code Cells:
    '''
    <Cell_0>
#Imports
import numpy as np
import pandas as pd
from scipy.stats import skew
from scipy.stats.stats import pearsonr
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
pd.options.display.max_columns = 50
sns.set_style('whitegrid')
%matplotlib inline

from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, LassoCV, LassoLarsCV, ElasticNet, Lasso
from sklearn.cross_validation import cross_val_score
import xgboost as xgb
from sklearn.feature_selection import SelectFromModel
<\Cell_0>
<Cell_1>
#importing data
train_DF = pd.read_csv('train.csv')
test_DF = pd.read_csv('test.csv')
train_DF.head()
<\Cell_1>
<Cell_2>
print("------Training Data Information-------\n")
train_DF.info()
print("\n\n------Test Data Information-------\n")
test_DF.info()
<\Cell_2>
<Cell_3>
#Getting dummies for all the non numeric data
train_DF = pd.get_dummies(train_DF)
test_DF = pd.get_dummies(test_DF)

#Fill in empty values with mean of each column
train_DF = train_DF.fillna(train_DF.mean())
test_DF = test_DF.fillna(test_DF.mean())
<\Cell_3>
<Cell_4>
#Define function for determining Tuning Parameter
def cv_error(model):
    cve= np.sqrt(-cross_val_score(model, X, Y, scoring="mean_squared_error", cv = 5))
    return(cve)
<\Cell