<Cell_0>
import pandas as pd
from bs4 import BeautifulSoup
import re
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
<\Cell_0>
<Cell_1>
#This downloads data for nltk analysis. Use if necessary.
#nltk.download()
<\Cell_1>
<Cell_2>
train = pd.read_csv('../input/labeledTrainData.tsv', header=0, delimiter='\t', quoting=3)
test = pd.read_csv('../input/testData.tsv', header=0, delimiter='\t', quoting=3)
<\Cell_2>
<Cell_3>
def text_to_words(text):
    """
    Extract words from text.
    """
    text = BeautifulSoup(text, 'lxml').get_text()
    letters = re.sub('[^a-zA-Z]', ' ', text)
    words = letters.lower().split()
    stops = set(stopwords.words('english')) 
    meaningful_words = [w for w in words if not w in stops]
    return (' '.join(meaningful_words))
<\Cell_3>
<Cell_4>
#Check that it works
print(text_to_words(train['review'][0]))
<\Cell_4>
<Cell_5>
def clean(a):
    """
    Cleaning data.
    """
    for i in range(0, a.size):
        yield text_to_words(a[i])
<\Cell_5>
<Cell_6>
vectorizer = CountVectorizer(analyzer = 'word',
                             tokenizer = None,
                             preprocessor = None,
                             stop_words = None,
                             max_df = 0.5,
                             max_features = 10000)
<\Cell_6>
<Cell_7>
train_reviews = list(clean(train['review']))
train_data_features = vectorizer.fit_transform(train_reviews)
test_reviews = list(clean(test['review'])) 
test_data_features = vectorizer.transform(test_reviews)
<\Cell_7>
<Cell_8>
Xtrain, Xtest, ytrain, ytest = train_test_split(train_data_features, train['sentiment'], test_size=0.20, random_state=36)
<\Cell_8>
<Cell_9>
mnb = MultinomialNB(alpha=0.0001)
y_val_m = mnb.fit(Xtrain, ytrain).predict_proba(Xtest)[:,1]
y_pred_m = mnb.fit(train_data_features, train['sentiment']).predict_proba(test_data_features)[:,1]

#Accuracy of prediction on validation set
roc_auc_score(ytest, y_val_m)
<\Cell_9>
<Cell_10>
#Random Forest is even better
forest = RandomForestClassifier(n_estimators=300, criterion = 'gini')
y_val_f = forest.fit(Xtrain, ytrain).predict_proba(Xtest)[:,1]
y_pred_f = forest.fit(train_data_features, train['sentiment']).predict_proba(test_data_features)[:,1]
roc_auc_score(ytest, y_val_f)
<\Cell_10>
<Cell_11>
#Ensemble of models seems to be the best.
roc_auc_score(ytest, y_val_m + y_val_f)
<\Cell_11>
<Cell_12>
output = pd.DataFrame(data={'id':test['id'], 'sentiment':y_pred_m + y_pred_f})

output.to_csv('Bag_of_Words_model.csv', index=False, quoting=3)
<\Cell_12>
