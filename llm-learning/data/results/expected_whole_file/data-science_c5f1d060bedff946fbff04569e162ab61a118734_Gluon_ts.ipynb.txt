<Cell_0>
pip install mxnet
<\Cell_0>
<Cell_1>
pip install gluonts
<\Cell_1>
<Cell_2>
# Third-party imports
%matplotlib inline
import mxnet as mx
from mxnet import gluon
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json
<\Cell_2>
<Cell_3>
from gluonts.dataset.repository.datasets import get_dataset, dataset_recipes
from gluonts.dataset.util import to_pandas
<\Cell_3>
<Cell_4>
print(f"Available datasets: {list(dataset_recipes.keys())}")
<\Cell_4>
<Cell_5>
dataset = get_dataset("m4_hourly", regenerate=True)
<\Cell_5>
<Cell_6>
entry = next(iter(dataset.train))
train_series = to_pandas(entry)
train_series.plot()
plt.grid(which="both")
plt.legend(["train series"], loc="upper left")
plt.show()
<\Cell_6>
<Cell_7>
entry = next(iter(dataset.test))
test_series = to_pandas(entry)
test_series.plot()
plt.axvline(train_series.index[-1], color='r') # end of train dataset
plt.grid(which="both")
plt.legend(["test series", "end of train series"], loc="upper left")
plt.show()
<\Cell_7>
<Cell_8>
N = 10  # number of time series
T = 100  # number of timesteps
prediction_length = 24
freq = "1H"
custom_dataset = np.random.normal(size=(N, T))
start = pd.Timestamp("01-01-2019", freq=freq)  # can be different for each time series
<\Cell_8>
<Cell_9>
from gluonts.dataset.common import ListDataset
<\Cell_9>
<Cell_10>
# train dataset: cut the last window of length "prediction_length", add "target" and "start" fields
train_ds = ListDataset([{'target': x, 'start': start} 
                        for x in custom_dataset[:, :-prediction_length]],
                       freq=freq)
# test dataset: use the whole dataset, add "target" and "start" fields
test_ds = ListDataset([{'target': x, 'start': start} 
                       for x in custom_dataset],
                      freq=freq)
<\Cell_10>
<Cell_11>
from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator
from gluonts.trainer import Trainer
<\Cell_11>
<Cell_12>
estimator = SimpleFeedForwardEstimator(
    num_hidden_dimensions=[10],
    prediction_length=dataset.metadata.prediction_length,
    context_length=100,
    freq=dataset.metadata.freq,
    trainer=Trainer(ctx="cpu", 
                    epochs=5, 
                    learning_rate=1e-3, 
                    num_batches_per_epoch=100
                   )
)
<\Cell_12>
<Cell_13>
predictor = estimator.train(dataset.train)
<\Cell_13>
<Cell_14>
from gluonts.evaluation.backtest import make_evaluation_predictions
<\Cell_14>
<Cell_15>
forecast_it, ts_it = make_evaluation_predictions(
    dataset=dataset.test,  # test dataset
    predictor=predictor,  # predictor
    num_samples=100,  # number of sample paths we want for evaluation
)
<\Cell_15>
<Cell_16>
forecasts = list(forecast_it)
tss = list(ts_it)
<\Cell_16>
<Cell_17>
ts_entry = tss[0]
<\Cell_17>
<Cell_18>
np.array(ts_entry[:5]).reshape(-1,)
<\Cell_18>
<Cell_19>
dataset_test_entry = next(iter(dataset.test))
<\Cell_19>
<Cell_20>
dataset_test_entry['target'][:5]
<\Cell_20>
<Cell_21>
forecast_entry = forecasts[0]
<\Cell_21>
<Cell_22>
def plot_prob_forecasts(ts_entry, forecast_entry):
    plot_length = 150 
    prediction_intervals = (50.0, 90.0)
    legend = ["observations", "median prediction"] + [f"{k}% prediction interval" for k in prediction_intervals][::-1]

    fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    ts_entry[-plot_length:].plot(ax=ax)  # plot the time series
    forecast_entry.plot(prediction_intervals=prediction_intervals, color='g')
    plt.grid(which="both")
    plt.legend(legend, loc="upper left")
    plt.show()
<\Cell_22>
<Cell_23>
plot_prob_forecasts(ts_entry, forecast_entry)
<\Cell_23>
<Cell_24>

<\Cell_24>
