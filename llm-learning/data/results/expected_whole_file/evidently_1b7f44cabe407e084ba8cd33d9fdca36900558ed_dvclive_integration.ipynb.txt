<Cell_0>
!pip uninstall -q -y sqlalchemy pyarrow ipython-sql pandas-gbq
<\Cell_0>
<Cell_1>
%%capture
!pip install -q dvc==3.25.0 dvclive==3.0.1 evidently==0.4.5 pandas==1.5.3
<\Cell_1>
<Cell_2>
!mkdir raw_data && \
 cd raw_data && \
 wget https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip && \
 unzip bike+sharing+dataset.zip
<\Cell_2>
<Cell_3>
import pandas as pd
<\Cell_3>
<Cell_4>
df = pd.read_csv("raw_data/day.csv", header=0, sep=',', parse_dates=['dteday'])
df.head()
<\Cell_4>
<Cell_5>
from evidently.pipeline.column_mapping import ColumnMapping
<\Cell_5>
<Cell_6>
data_columns = ColumnMapping()
data_columns.numerical_features = ['weathersit', 'temp', 'atemp', 'hum', 'windspeed']
data_columns.categorical_features = ['holiday', 'workingday']
<\Cell_6>
<Cell_7>
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset
<\Cell_7>
<Cell_8>
def eval_drift(reference, production, column_mapping):
    data_drift_report = Report(metrics=[DataDriftPreset()])
    data_drift_report.run(
        reference_data=reference, current_data=production, column_mapping=column_mapping
    )
    report = data_drift_report.as_dict()

    drifts = []

    for feature in (
        column_mapping.numerical_features + column_mapping.categorical_features
    ):
        drifts.append(
            (
                feature,
                report["metrics"][1]["result"]["drift_by_columns"][feature][
                    "drift_score"
                ],
            )
        )

    return drifts

<\Cell_8>
<Cell_9>
#set reference dates
reference_dates = ('2011-01-01 00:00:00','2011-01-28 23:00:00')

#set experiment batches dates
experiment_batches = [
    ('2011-01-01 00:00:00','2011-01-29 23:00:00'),
    ('2011-01-29 00:00:00','2011-02-07 23:00:00'),
    ('2011-02-07 00:00:00','2011-02-14 23:00:00'),
    ('2011-02-15 00:00:00','2011-02-21 23:00:00'),
]
<\Cell_9>
<Cell_10>
!git config --global user.email "you@example.com"
!git config --global user.name "Your Name"
<\Cell_10>
<Cell_11>
from dvclive import Live
<\Cell_11>
<Cell_12>
# Setup a git repo with dvc

%cd /content
!rm -rf experiments && mkdir experiments
%cd experiments

!git init
!git add .gitignore
!git commit -m "Init repo"
!dvc init
!git commit -m "Init DVC"
<\Cell_12>
<Cell_13>
with Live(report="notebook") as live:
    for date in experiment_batches:
        live.log_param("begin", date[0])
        live.log_param("end", date[1])

        metrics = eval_drift(
            df.loc[df.dteday.between(reference_dates[0], reference_dates[1])],
            df.loc[df.dteday.between(date[0], date[1])],
            column_mapping=data_columns,
        )

        for feature in metrics:
            live.log_metric(feature[0], round(feature[1], 3))

        live.next_step()
<\Cell_13>
<Cell_14>
!dvc plots show
<\Cell_14>
<Cell_15>
import IPython
IPython.display.HTML(filename='dvc_plots/index.html')
<\Cell_15>
<Cell_16>
# Setup a git repo with dvc

%cd /content
!rm -rf experiments && mkdir experiments
%cd experiments

!git init
!git add .gitignore
!git commit -m "Init repo"
!dvc init
!git commit -m "Init DVC"
<\Cell_16>
<Cell_17>
from dvclive import Live

for step, date in enumerate(experiment_batches):
    with Live() as live:
        live.log_param("step", step)
        live.log_param("begin", date[0])
        live.log_param("end", date[1])

        metrics = eval_drift(
            df.loc[df.dteday.between(reference_dates[0], reference_dates[1])],
            df.loc[df.dteday.between(date[0], date[1])],
            column_mapping=data_columns,
        )

        for feature in metrics:
            live.log_metric(feature[0], round(feature[1], 3))

<\Cell_17>
<Cell_18>
import dvc.api

pd.DataFrame(dvc.api.exp_show())
<\Cell_18>
<Cell_19>
!dvc exp show
<\Cell_19>
<Cell_20>

<\Cell_20>
