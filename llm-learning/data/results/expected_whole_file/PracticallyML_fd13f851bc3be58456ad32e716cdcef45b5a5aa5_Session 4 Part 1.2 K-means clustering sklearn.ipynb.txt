<Cell_0>
# K-Means Clustering

# Importing the libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
<\Cell_0>
<Cell_1>
# Importing the cars.csv dataset
dataset = pd.read_csv('data/cars.csv')

#print first 10 rows of X
dataset.head(10)

#construct X
X = dataset.iloc[:, :-1]

X = X.convert_objects(convert_numeric=True)

X.head()
<\Cell_1>
<Cell_2>
#print first 5 rows of X
<\Cell_2>
<Cell_3>
#describe X
X.describe()
<\Cell_3>
<Cell_4>

<\Cell_4>
<Cell_5>
X.isnull().any()
# Eliminating null values

for col in X.columns:
    X[col] = X[col].fillna(X[col].mean())

# X.columns
# X[' cubicinches'] = X[' cubicinches'].fillna(X[' cubicinches'].mean())
X.describe()
# X[' cubicinches'].fillna
<\Cell_5>
<Cell_6>
# Using the elbow method to find  the optimal number of clusters

#import kmeans 
from sklearn.cluster import KMeans
wcss = []

for i in range(1,11):
    #initialise k means instance
    kmeans = KMeans(n_clusters=i)
    #fit the data
    kmeans.fit(X)
    
    wcss.append(kmeans.inertia_)
    
#plot cluster vs wcss
plt.plot(range(1, 11), wcss)
<\Cell_6>
<Cell_7>
# Applying k-means to the cars dataset
kmeans = KMeans(n_clusters=3,init='k-means++',max_iter=300,n_init=10,random_state=0) 
y_kmeans = kmeans.fit_predict(X)

X = X.as_matrix(columns=None)
# type(X)
<\Cell_7>
<Cell_8>
y_kmeans
<\Cell_8>
<Cell_9>
X.head()
<\Cell_9>
<Cell_10>
# Visualising the clusters
plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0,1],s=100,c='red',label='US')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1,1],s=100,c='blue',label='Japan')
plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2,1],s=100,c='green',label='Europe')
plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=300,c='yellow',label='Centroids')
plt.title('Clusters of car brands')
plt.legend()
plt.show()
<\Cell_10>
<Cell_11>

<\Cell_11>
